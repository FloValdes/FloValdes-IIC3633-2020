## Comentario: BPR: Bayesian personalized ranking from implicit feedback

Este paper plantea que se han propuesto muchos algoritmos para calcular recomendaciones, todos estos basados en calcular y optimizar una predicción para una calificación de un item de determinado usuario. Sin embargo, estos métodos también se utilizan para hacer _rankings_ de items, cuando no fueron optimizados para eso. Los autores proponen un método basado en estadística bayesiana y en sampleo con _bootstraping_ que utiliza _feedback_ implícito y se puede aplicar a cualquier método ya implementado que predice ratings, como uknn, iknn o descomposición matricial. 

Los autores también plantean el problema de que el _feedback_ implícito solo tiene datos positivos, ya que los negativos corresponden a una parte de los datos desconocidos. El problema de seguir un enfoque como el del paper anterior, de entregar valores positivos a los valores conocidos y valores negativos (cero) a los desconocidos, es que luego se espera que el modelo rankee items desconocidos y estos solo serán ceros. Este problema se da específicamente por la tarea de rankeo, pero no era un problema en el paper anterior. Para solucionarlo, se plantea que si un item tiene feedback, entonces se asumirá que el usuario prefiere ese item a los que no conoce. Luego, los datos desconocidos que el modelo deberá predecir serán pares de items en los cuales ambos tienen _feedback_ o ambos son desconocidos. Si bien el supuesto propuesto parece adecuado (en promedio, es más probable que a alguien le guste más algo que vio que algo desconocido que puede o no gustarle), quizás sería útil añadir alguna noción como la de confianza del paper anterior, en donde hay pares cuyo ranking estamos más seguros que otros.

Me parece positivo que hicieran un algoritmo genérico que puede adaptarse a cualquier algoritmo que produzca predicciones de _ratings_, como iknn o svd. También me parece buena idea utilizar tripletas random de (usuario, item1, item2) para el entrenamiento, en vez de entrenar por usuarios, para evitar el problema de que un par (usuario, item) domina la convergencia del gradiente. Por último, me parece novedoso que utilizaran un sampleo con reemplazo y no se guiaran por las clásicas épocas de entrenamiento en las que se pasa por todo el dataset de training, diciendo que muchas veces su algoritmo convergía antes.

Para resumir la principal enseñanza del paper, destaco esta frase: "Our results show the importance of optimizing model parameters to the right criterion". Si nuestra tarea es rankear items, es importante que estemos optimizando para eso y no simplemente pare predecir ratings.