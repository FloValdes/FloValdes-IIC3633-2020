## Commentary: Item-Based Collaborative Filtering Recommendation Algorithms

User Based Collaborative Filtering has a scalability problem: computing the _k_ nearest neighbors when there are millions of users is computationally expensive. This paper presents a different approach, item based collaborative filtering. IBCF consists of computing the similarity of every pair of items with some function (like adjusted cosine) that receives the vector of ratings for both items, extracted from all the user’s ratings that rated both items. After that, the prediction is made with a certain amount of similar items, their similarity score and the rating the active user gave to those items. Different experiments were made to get the ideal parameters like neighborhood size, model size or the similarity function. This approach has better performance than user based CF because the number of items is usually much lower than the number of users, thus reducing the number of calculations, but also because the items are more static and it’s possible to precompute a model with a reduced number of similar items. It also performed better than UBCF when measured with MAE and ROC.

A criticism I have about the paper is that the problem of sparsity of the data does not seem to be addressed. At the beginning they claim that user based collaborative filtering could have poor accuracy due to users rating a very small sample of the items and the system not being able to find recommendations for the user. This problem seems to apply to item based collaborative filtering as well and could also get worse with limiting the number of items used to create the model, which is something they do towards the end of their experiments. It is not clear what they do when in the _n_ most similar items chosen there are no ratings from the active user.

Another issue, that is strongly connected to my last point, is the fact that IBCF can easily fall into just recommending items in a “comfort zone” for the active user. If, for example, a certain user has never watched romance movies, this system will probably have no similar items for any romance movie and therefore would never recommend this type of movie to the user, and would probably just keep recommending very similar movies to the ones the user has already watched and liked. This doesn’t seem to be a problem with user based collaborative filtering, because it’s easier to find another user who likes the movies the active user likes that has also watched and enjoyed some romance movies. With item based, though, because the similarity of two items is computed with all the users that rated those two items, it’s easy to lose the subtle relationships between a certain sci-fi movie and a certain romance movie that some people may see, and just fall into big categories. This may create the problem where the system is just recommending the ‘safe bets’ rather than the movies the user may enjoy more but that are different to what they see. I would think that a recommending system that suggests the best movies for me to watch, regardless of their similarity with what I’ve already watched would keep me engaged with the content for longer, mainly due to recommending me what is actually the best for me, but also because of the variety and the unknown. It is, however, something hard to measure. The proposed measurements MAE and ROC are not enough. MAE could take this into account to some degree when users have ratings for items that are not similar to what they they mostly rate, but the quality, measured with MAE, was better than user based recommendations, so maybe people usually don’t really step out of their comfort zone that much, so it brings the question if a recommender system should push them in that direction or not.